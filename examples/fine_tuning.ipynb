{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f8c75a16",
   "metadata": {},
   "source": [
    "# Fine-tune the pretrained CHGNet for better accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62b96d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "# install CHGNet (only needed on Google Colab or if you didn't install CHGNet yet)\n",
    "!pip install chgnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ead933c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHGNet initialized with 400,438 parameters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from pymatgen.core import Structure\n",
    "\n",
    "from chgnet.model import CHGNet\n",
    "\n",
    "chgnet = CHGNet.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16eeae1e",
   "metadata": {},
   "source": [
    "## 1. Prepare Training Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208fa4aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    from chgnet import ROOT\n",
    "\n",
    "    lmo = Structure.from_file(f\"{ROOT}/examples/mp-18767-LiMnO2.cif\")\n",
    "except Exception:\n",
    "    from urllib.request import urlopen\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/CederGroupHub/chgnet/main/examples/mp-18767-LiMnO2.cif\"\n",
    "    cif = urlopen(url).read().decode(\"utf-8\")\n",
    "    lmo = Structure.from_str(cif, fmt=\"cif\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec2524a",
   "metadata": {},
   "source": [
    "We create a dummy fine-tuning dataset by using CHGNet prediction with some random noise.\n",
    "For your purpose of fine-tuning to a specific chemical system or AIMD data, please modify the block below\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667d849f",
   "metadata": {},
   "outputs": [],
   "source": [
    "structures, energies_per_atom, forces, stresses, magmoms = [], [], [], [], []\n",
    "\n",
    "for _ in range(100):\n",
    "    structure = lmo.copy()\n",
    "    # stretch the cell by a small amount\n",
    "    structure.apply_strain(np.random.uniform(-0.1, 0.1, size=3))\n",
    "    # perturb all atom positions by a small amount\n",
    "    structure.perturb(0.1)\n",
    "\n",
    "    pred = chgnet.predict_structure(structure)\n",
    "\n",
    "    structures.append(structure)\n",
    "    energies_per_atom.append(pred[\"e\"] + np.random.uniform(-0.1, 0.1, size=1))\n",
    "    forces.append(pred[\"f\"] + np.random.uniform(-0.01, 0.01, size=pred[\"f\"].shape))\n",
    "    stresses.append(\n",
    "        pred[\"s\"] * -10 + np.random.uniform(-0.05, 0.05, size=pred[\"s\"].shape)\n",
    "    )\n",
    "    magmoms.append(pred[\"m\"] + np.random.uniform(-0.03, 0.03, size=pred[\"m\"].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "052536e6",
   "metadata": {},
   "source": [
    "Note that the stress output from CHGNet is in unit of GPa, here the -10 unit conversion\n",
    "modifies it to be kbar in VASP raw unit. We do this since by default, StructureData\n",
    "dataset class takes in VASP units.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea8393e",
   "metadata": {},
   "source": [
    "## 2. Define DataSet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd9f19e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from chgnet.data.dataset import StructureData, get_train_val_test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e96c4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 structures imported\n"
     ]
    }
   ],
   "source": [
    "dataset = StructureData(\n",
    "    structures=structures,\n",
    "    energies=energies_per_atom,\n",
    "    forces=forces,\n",
    "    stresses=stresses,  # can be None\n",
    "    magmoms=magmoms,  # can be None\n",
    ")\n",
    "train_loader, val_loader, test_loader = get_train_val_test_loader(\n",
    "    dataset, batch_size=8, train_ratio=0.9, val_ratio=0.05\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dc5ad3",
   "metadata": {},
   "source": [
    "Here the `batch_size` is defined to be 8 for small GPU-memory. If > 10 GB memory is available, we highly recommend to increase `batch_size` for better speed.\n",
    "\n",
    "If you have very large numbers of structures (which is typical for AIMD), putting them all in a python list can quickly run into memory issues. In this case we highly recommend you to pre-convert all the structures into graphs and save them as shown in `examples/make_graphs.py`. Then directly train CHGNet by loading the graphs from disk instead of memory using the `GraphData` class defined in `data/dataset.py`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99445e44",
   "metadata": {},
   "source": [
    "## 3. Define model and trainer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e77bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CHGNet initialized with 400,438 parameters\n"
     ]
    }
   ],
   "source": [
    "from chgnet.trainer import Trainer\n",
    "\n",
    "# Load pretrained CHGNet\n",
    "chgnet = CHGNet.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3afbc75",
   "metadata": {},
   "source": [
    "It's optional to freeze the weights inside some layers. This is a common technique to retain the learned knowledge during fine-tuning in large pretrained neural networks. You can choose the layers you want to freeze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e69c71b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optionally fix the weights of some layers\n",
    "for layer in [\n",
    "    chgnet.atom_embedding,\n",
    "    chgnet.bond_embedding,\n",
    "    chgnet.angle_embedding,\n",
    "    chgnet.bond_basis_expansion,\n",
    "    chgnet.angle_basis_expansion,\n",
    "    chgnet.atom_conv_layers[:-1],\n",
    "    chgnet.bond_conv_layers,\n",
    "    chgnet.angle_layers,\n",
    "]:\n",
    "    for param in layer.parameters():\n",
    "        param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52511a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "trainer = Trainer(\n",
    "    model=chgnet,\n",
    "    targets=\"efsm\",\n",
    "    optimizer=\"Adam\",\n",
    "    scheduler=\"CosLR\",\n",
    "    criterion=\"MSE\",\n",
    "    epochs=5,\n",
    "    learning_rate=0,\n",
    "    use_device=\"cpu\",\n",
    "    print_freq=6,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f47fca4",
   "metadata": {},
   "source": [
    "## 4. Start training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a990258",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begin Training: using cpu device\n",
      "training targets: efsm\n",
      "Epoch: [0][1/12]\tTime (0.353)  Data (0.012)  Loss 0.0041 (0.0041)  MAEs:  e 0.060 (0.060)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.014 (0.014)  \n",
      "Epoch: [0][6/12]\tTime (0.401)  Data (0.011)  Loss 0.0048 (0.0043)  MAEs:  e 0.059 (0.059)  f 0.005 (0.005)  s 0.003 (0.003)  m 0.014 (0.014)  \n",
      "Epoch: [0][12/12]\tTime (0.386)  Data (0.015)  Loss 0.0015 (0.0041)  MAEs:  e 0.035 (0.056)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.012 (0.014)  \n",
      "*   e_MAE (0.060) \tf_MAE (0.005) \ts_MAE (0.002) \tm_MAE (0.013) \t\n",
      "Epoch: [1][1/12]\tTime (0.357)  Data (0.000)  Loss 0.0025 (0.0025)  MAEs:  e 0.043 (0.043)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.015 (0.015)  \n",
      "Epoch: [1][6/12]\tTime (0.357)  Data (0.000)  Loss 0.0042 (0.0042)  MAEs:  e 0.055 (0.058)  f 0.005 (0.005)  s 0.003 (0.003)  m 0.012 (0.014)  \n",
      "Epoch: [1][12/12]\tTime (0.329)  Data (0.000)  Loss 0.0005 (0.0041)  MAEs:  e 0.017 (0.056)  f 0.005 (0.005)  s 0.003 (0.002)  m 0.015 (0.014)  \n",
      "*   e_MAE (0.060) \tf_MAE (0.005) \ts_MAE (0.002) \tm_MAE (0.013) \t\n",
      "Epoch: [2][1/12]\tTime (0.346)  Data (0.000)  Loss 0.0042 (0.0042)  MAEs:  e 0.060 (0.060)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.013 (0.013)  \n",
      "Epoch: [2][6/12]\tTime (0.331)  Data (0.000)  Loss 0.0030 (0.0036)  MAEs:  e 0.042 (0.052)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.015 (0.014)  \n",
      "Epoch: [2][12/12]\tTime (0.330)  Data (0.000)  Loss 0.0064 (0.0041)  MAEs:  e 0.077 (0.056)  f 0.005 (0.005)  s 0.003 (0.002)  m 0.014 (0.014)  \n",
      "*   e_MAE (0.060) \tf_MAE (0.005) \ts_MAE (0.002) \tm_MAE (0.013) \t\n",
      "Epoch: [3][1/12]\tTime (0.350)  Data (0.000)  Loss 0.0025 (0.0025)  MAEs:  e 0.042 (0.042)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.014 (0.014)  \n",
      "Epoch: [3][6/12]\tTime (0.361)  Data (0.000)  Loss 0.0043 (0.0043)  MAEs:  e 0.059 (0.057)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.015 (0.014)  \n",
      "Epoch: [3][12/12]\tTime (0.338)  Data (0.000)  Loss 0.0050 (0.0041)  MAEs:  e 0.070 (0.056)  f 0.005 (0.005)  s 0.003 (0.002)  m 0.012 (0.014)  \n",
      "*   e_MAE (0.060) \tf_MAE (0.005) \ts_MAE (0.002) \tm_MAE (0.013) \t\n",
      "Epoch: [4][1/12]\tTime (0.365)  Data (0.000)  Loss 0.0055 (0.0055)  MAEs:  e 0.068 (0.068)  f 0.005 (0.005)  s 0.002 (0.002)  m 0.012 (0.012)  \n",
      "Epoch: [4][6/12]\tTime (0.342)  Data (0.000)  Loss 0.0028 (0.0040)  MAEs:  e 0.048 (0.056)  f 0.005 (0.005)  s 0.002 (0.003)  m 0.015 (0.014)  \n",
      "Epoch: [4][12/12]\tTime (0.331)  Data (0.000)  Loss 0.0020 (0.0041)  MAEs:  e 0.033 (0.056)  f 0.005 (0.005)  s 0.003 (0.002)  m 0.011 (0.014)  \n",
      "*   e_MAE (0.060) \tf_MAE (0.005) \ts_MAE (0.002) \tm_MAE (0.013) \t\n",
      "---------Evaluate Model on Test Set---------------\n",
      "**  e_MAE (0.060) \tf_MAE (0.005) \ts_MAE (0.003) \tm_MAE (0.013) \t\n"
     ]
    }
   ],
   "source": [
    "trainer.train(train_loader, val_loader, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169de30e",
   "metadata": {},
   "source": [
    "After training, the trained model can be found in the directory of today's date. Or it can be accessed by:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa383b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = trainer.model\n",
    "best_model = trainer.best_model  # best model based on validation energy MAE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcc09b4",
   "metadata": {},
   "source": [
    "## Extras 1: GGA / GGA+U compatibility\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a977284",
   "metadata": {},
   "source": [
    "### Q: Why and when do you care about this?\n",
    "\n",
    "**When**: If you want to fine-tune the pretrained CHGNet with your own GGA+U VASP calculations, and you want to keep your VASP energy compatible to the pretrained dataset. In case your dataset is so large that the pretrained knowledge does not matter to you, you can ignore this.\n",
    "\n",
    "**Why**: CHGNet is trained on both GGA and GGA+U calculations from Materials Project. And there has been developed methods in solving the compatibility between GGA and GGA+U calculations which makes the energies universally applicable for cross-chemistry comparison and phase-diagram constructions. Please refer to:\n",
    "\n",
    "https://journals.aps.org/prb/abstract/10.1103/PhysRevB.84.045115\n",
    "\n",
    "Below we show an example to apply the compatibility.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf8c3e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The raw total energy from VASP of LMO is: -58.97 eV\n"
     ]
    }
   ],
   "source": [
    "# Imagine this is the VASP raw energy\n",
    "vasp_raw_energy = -58.97\n",
    "\n",
    "print(f\"The raw total energy from VASP of LMO is: {vasp_raw_energy} eV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce51fa9",
   "metadata": {},
   "source": [
    "You can look for the energy correction applied to each element in :\n",
    "\n",
    "https://github.com/materialsproject/pymatgen/blob/v2023.2.28/pymatgen/entries/MP2020Compatibility.yaml\n",
    "\n",
    "Here LiMnO2 applies to both Mn in transition metal oxides correction and oxide correction.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a575d6a8",
   "metadata": {},
   "source": [
    "To demystify `MaterialsProject2020Compatibility`, basically all that's happening is:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2262bbd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The corrected total energy after MP2020 = -65.05 eV\n"
     ]
    }
   ],
   "source": [
    "Mn_correction_in_TMO = -1.668\n",
    "oxide_correction = -0.687\n",
    "_, num_Mn, num_O = lmo.composition.values()\n",
    "\n",
    "\n",
    "corrected_energy = (\n",
    "    vasp_raw_energy + num_Mn * Mn_correction_in_TMO + num_O * oxide_correction\n",
    ")\n",
    "print(f\"The corrected total energy after MP2020 = {corrected_energy:.4} eV\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5a7346",
   "metadata": {},
   "source": [
    "You can also apply the `MaterialsProject2020Compatibility` through pymatgen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8169c61c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total energy of LMO after MP2020Compatibility correction = -65.05 eV\n"
     ]
    }
   ],
   "source": [
    "from pymatgen.entries.compatibility import MaterialsProject2020Compatibility\n",
    "from pymatgen.entries.computed_entries import ComputedStructureEntry, ComputedEntry\n",
    "\n",
    "params = {\"hubbards\": {\"Mn\": 3.9, \"O\": 0, \"Li\": 0}, \"run_type\": \"GGA+U\"}\n",
    "\n",
    "cse = ComputedStructureEntry(lmo, vasp_raw_energy, parameters=params)\n",
    "\n",
    "MaterialsProject2020Compatibility(check_potcar=False).process_entries(cse)\n",
    "print(\n",
    "    f\"The total energy of LMO after MP2020Compatibility correction = {cse.energy:.4} eV\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deeb3814",
   "metadata": {},
   "source": [
    "Now use this corrected energy as labels to tune CHGNet, you're good to go!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c36fe61",
   "metadata": {},
   "source": [
    "## Extras 2: AtomRef\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb93bc0",
   "metadata": {},
   "source": [
    "If you want to fine tune CHGNet to DFT labels that are even more incompatible with Materials Project, like r2SCAN functional, or other DFTs like Gaussian or QE. More trick has to be done to withhold the most amount of information learned during pretraining.\n",
    "\n",
    "For example, formation energy can be a well-compatible property across different functionals. In CHGNet, we use a Atom_Ref operation, which is a formation-energy-like calculation for per-element contribution to the total energy.\n",
    "\n",
    "When fine-tuning to other functionals that might have large discrepancy in elemental energies. We recommend you to refit the AtomRef. So that the finetuning on the graph layers can be focused on energy contribution from atom-atom interaction instead of meaningless atom reference energies.\n",
    "\n",
    "Below I will show an example to refit the AtomRef layer:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaf7838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The pretrained Atom_Ref (per atom reference energy):\n",
      "Parameter containing:\n",
      "tensor([[ -3.4431,  -0.1279,  -2.8300,  -3.4737,  -7.4946,  -8.2354,  -8.1611,\n",
      "          -8.3861,  -5.7498,  -0.0236,  -1.7406,  -1.6788,  -4.2833,  -6.2002,\n",
      "          -6.1315,  -5.8405,  -3.8795,  -0.0703,  -1.5668,  -3.4451,  -7.0549,\n",
      "          -9.1465,  -9.2594,  -9.3514,  -8.9843,  -8.0228,  -6.4955,  -5.6057,\n",
      "          -3.4002,  -0.9217,  -3.2499,  -4.9164,  -4.7810,  -5.0191,  -3.3316,\n",
      "           0.5130,  -1.4043,  -3.2175,  -7.4994,  -9.3816, -10.4386,  -9.9539,\n",
      "          -7.9555,  -8.5440,  -7.3245,  -5.2771,  -1.9014,  -0.4034,  -2.6002,\n",
      "          -4.0054,  -4.1156,  -3.9928,  -2.7003,   2.2170,  -1.9671,  -3.7180,\n",
      "          -6.8133,  -7.3502,  -6.0712,  -6.1699,  -5.1471,  -6.1925, -11.5829,\n",
      "         -15.8841,  -5.9994,  -6.0798,  -5.9513,  -6.0400,  -5.9773,  -2.5091,\n",
      "          -6.0767, -10.6666, -11.8761, -11.8491, -10.7397,  -9.6100,  -8.4755,\n",
      "          -6.2070,  -3.0337,   0.4726,  -1.6425,  -3.1295,  -3.3328,  -0.1221,\n",
      "          -0.3448,  -0.4364,  -0.1661,  -0.3680,  -4.1869,  -8.4233, -10.0467,\n",
      "         -12.0953, -12.5228, -14.2530]])\n"
     ]
    }
   ],
   "source": [
    "print(\"The pretrained Atom_Ref (per atom reference energy):\")\n",
    "for param in chgnet.composition_model.parameters():\n",
    "    print(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1caed7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A list of structures / graphs\n",
    "structures = [\n",
    "    lmo,\n",
    "    Structure(\n",
    "        species=[\"Li\", \"Mn\", \"Mn\", \"O\", \"O\", \"O\"],\n",
    "        lattice=np.random.rand(3, 3),\n",
    "        coords=np.random.rand(6, 3),\n",
    "    ),\n",
    "    Structure(\n",
    "        species=[\"Li\", \"Li\", \"Mn\", \"O\", \"O\", \"O\"],\n",
    "        lattice=np.random.rand(3, 3),\n",
    "        coords=np.random.rand(6, 3),\n",
    "    ),\n",
    "    Structure(\n",
    "        species=[\"Li\", \"Mn\", \"Mn\", \"O\", \"O\", \"O\", \"O\"],\n",
    "        lattice=np.random.rand(3, 3),\n",
    "        coords=np.random.rand(7, 3),\n",
    "    ),\n",
    "]\n",
    "\n",
    "# A list of energy_per_atom values (random values here)\n",
    "energies_per_atom = [5.5, 6, 4.8, 5.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aa551c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We initialize another identical AtomRef layers\n",
      "tensor([[-3.4431, -0.1279, -2.8300]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "from chgnet.model.composition_model import AtomRef\n",
    "\n",
    "print(\"We initialize another identical AtomRef layers\")\n",
    "new_atom_ref = AtomRef(is_intensive=True)\n",
    "new_atom_ref.initialize_from_MPtrj()\n",
    "for param in new_atom_ref.parameters():\n",
    "    print(param[:, :3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28726cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After refitting, the AtomRef looks like:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0000e+00,  0.0000e+00,  4.2667e+00, -3.3299e-15,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  2.9999e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  1.1467e+01,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "new_atom_ref.fit(structures, energies_per_atom)\n",
    "print(\"After refitting, the AtomRef looks like:\")\n",
    "for param in new_atom_ref.parameters():\n",
    "    print(param)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
